import os
from datasets import load_dataset
import pyarrow as pa
import pyarrow.parquet as pq


def safe_sample_and_save(dataset_path, output_path, sample_size=1000, seed=42):
    try:
        from fastparquet import ParquetFile
        dataset = ParquetFile(dataset_path)
        df = dataset.to_pandas()

        # dfé‡‡æ ·
        sampled = df.sample(n=sample_size, random_state=seed)

        sampled_table = pa.Table.from_pandas(sampled)

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # ä¿å­˜ä¸ºParquet
        pq.write_table(sampled_table, output_path, compression='snappy')
        print(f"ğŸ¯ é‡‡æ ·å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {os.path.abspath(output_path)}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB")
        print(f"ğŸ“‹ å®é™…é‡‡æ ·æ•°é‡: {sampled_table.num_rows}")  # éªŒè¯æ ·æœ¬é‡

    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        raise


# ä½¿ç”¨ç¤ºä¾‹
safe_sample_and_save(
    dataset_path="./rlpr_train.parquet",
    output_path="./dist_entropy_rlpr_1k.parquet",
    sample_size=1000,
    seed=42
)